# 概要
221QのHumanAugmentedテーマで何をやるか決める
# 214Qの反省
## やったこと
- 聞きたいものが大きく聞こえる耳、聞きたくないものが聞こえない耳のプロトタイプ作成
- フォルマント変換を用いた聞きたい声で聞こえる耳のプロトタイプ作成
## 反省
### 聞きたいものが聞こえる耳、聞きたくないものが聞こえない耳
- 聞きたくないものを聞かない、はできているが、聞きたくない部分だけ聞かないということができない（全てが聞こえなくなってしまう）
- 聞きたいものを聞くという場合、単純にゲインを大きくしてしまうとかなり不快に感じる。
- 音声認識機能について
    - 会話や音がずっと流れている場合に会話の途切れが見つからずテキスト化されない
    - 検閲ワードを検出した瞬間は検閲できない
### デモを通してもらったアイデア・思いついたアイデア
- 喋れない（聞こえない）情報があった状態でコミュニケーションを行っても、当人たちも全く気付かないままコミュニケーションを続けられるとしたら面白い？
- カクテルパーティー効果みたいなのを減少させて、前の人の情報に集中するデバイス(SSB)
- 誰かが呼んだ時にだけ外界の情報を聞くようにしたら便利そう（みやさん）
- 声紋特定ができれば検閲ワードに引っかかりやすい人間、すなわち良い情報を持っている人間、NGワードを発しやすい人間などを特定できるかも(SSB)←これ面白そう（なりちゃん）
    - 声紋特定が厳しかったら、視覚情報から顔認証を行い、音の定位特定で会話をその人に紐付けるみたいなことできそう！！！！（SSB）
- どういう頻度でどういう単語が出るのか？わかるだけでもその人の色々な情報がみえるのではないか？（天野さん）
- ユーザの位置情報と組み合わせれば、検閲ワード検索によて、場のコミュニケーションを可視化し、そこが自分にとって生きやすいコミュニティか、生きづらいコミュニティか評価できるかも？（佐々部）
- 目の前の人物の特定と、SSTによる会話情報のバックアップを組み合わせられれば、その人がどういうことを喋る人間か？自分とどんなことを喋った人間かログが取れるかも
    - リアルなコミュニケーションをギャルゲー化できる
        - 喋ったことのログを取る
        - ログからその人がどんなことに興味がある人間かわかる
        - 会話中にこんなことを話したら？みたいなレコメンドがかかる
# 221Qでやりたいこと
## やりたいこと（候補）
- 214Qでは素朴なレベルでの耳拡張・耳減衰を行った。そこから単純なゲインの増強では不快感があるし、NGワード検閲による耳感覚減少では、全ての音声をシャットアウトしてしまうためコミュニケーションが困難になってしまうことがわかった。
- それを踏まえて221Qでは、聞きたい情報が発せられる特定の方向に耳を集中させ、聞きたくない情報がある方向の聴覚情報は減衰させるというアプローチをとる
- 一方で音源の方向が推定できれば、ある音源に集中して音を収集するということが可能なはずである。そこから声紋推定ができればその人物がどのような情報を持っているか判別することも可能であると思われる。よって声紋推定についても調べてみる
- また人物特定（OpenCV＋Dlib）と合わせて、この人が何こんなことを言っていたということを音声＋顔で認識できたらとてもいい
- これができれば騒音環境の中で話を聞きたい人物に耳を集中することができるなどの活用方法があると思われる
## 決定テーマ
1. ある方向の音声を増強し、それ以外の方向の音声を減衰させることによって、耳の認識を補助するデバイスの開発
2. 1Qで培ったSSTの技術やdlibでの顔認識技術を使って、音声のライフログを取る、人類ギャルゲー化計画
## 具体的な調査事項
- Respeakerを用いた音源音源定位の調査
- Respeakerもしくは回転する指向性マイク等を使った特定の方向の音声を取ってくる技術の調査
- 声紋認識技術の調査
- 画像からの人物特定技術の調査